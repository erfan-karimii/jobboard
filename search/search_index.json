{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to Jobboard documentation About Jobboard is an online recruiting platform API designed to streamline the hiring process. Its primary goal is to simplify recruitment while handling high traffic loads efficiently. The platform is engineered to manage high-pressure situations by maintaining optimal performance with minimal response times, ensuring a smooth and responsive experience for both recruiters and job seekers. Learn more about how we achieve this. Installation git clone https://github.com/erfan-karimii/jobboard cd jobboard docker compose -f docker-compose-dev.yaml up Note: Ensure that ports 5000, 25, and 143 are open, as they are required for SMTP4Dev. Why This Project Stands Out use locust to handel high load pressure use celery for handling background processing and task scheduling cash strategies Hardware configuration Ram: 8GB single channel hard: 128GB SSD cpu: 8core os: ubuntu server","title":"Home"},{"location":"#welcome-to-jobboard-documentation","text":"","title":"Welcome to Jobboard documentation"},{"location":"#about","text":"Jobboard is an online recruiting platform API designed to streamline the hiring process. Its primary goal is to simplify recruitment while handling high traffic loads efficiently. The platform is engineered to manage high-pressure situations by maintaining optimal performance with minimal response times, ensuring a smooth and responsive experience for both recruiters and job seekers. Learn more about how we achieve this.","title":"About"},{"location":"#installation","text":"git clone https://github.com/erfan-karimii/jobboard cd jobboard docker compose -f docker-compose-dev.yaml up Note: Ensure that ports 5000, 25, and 143 are open, as they are required for SMTP4Dev.","title":"Installation"},{"location":"#why-this-project-stands-out","text":"use locust to handel high load pressure use celery for handling background processing and task scheduling cash strategies","title":"Why This Project Stands Out"},{"location":"accounting/","text":"Accounting Authentication and Authorization We have chosen JWT (JSON Web Token) as our authentication mechanism due to its strong security features and efficient performance. For implementation, we use the Simple JWT package, which provides a convenient and customizable solution for managing tokens. Roles: Superuser: Has full access to the admin panel and all information across the platform. Company: Designed for company customers to manage job postings and handle applications. User: Intended for job seekers who wish to create profiles, browse, and apply for jobs. flow for job seekers: User Authentication: To sign up or log in to our application, users can interact with the /account/user/login endpoint. This endpoint accepts the user's email, which should be included in the body of the request. Handling New Users: If the email provided is new (i.e., not yet registered), a new user object is created in the database with that email. Once the account is successfully created, a JWT (JSON Web Token) is generated and sent to the provided email for authentication purposes. Profile Creation: Our Django application has a signal that automatically creates a user profile whenever a new account is registered. This eliminates the need to query the user table for details, as the profile data will be managed in a separate table. flow for company customer: Account Creation: Company customers must contact our support team to have an account created. The support team will ensure that the account is set up with the necessary profile details. There is no public endpoint available for company customers to create accounts themselves. Login Process: Once the account is created by support, company customers can log in using their company email through the standard login process. model NEED FURTHER RESEARCH schema Full Schema Testing integration test This app has been thoroughly tested to ensure full functionality and reliability load test The most critical endpoint in this section is user sign-up, due to its role in writing data to the database. We focused extensively on this endpoint by simulating the creation of 2 million users with randomly generated emails using Locust. Statistics indicate that under heavy load, the endpoint performs with a 99th percentile latency of 100 ms and an average latency of 70 ms, which meets our performance expectations. For more details on how we implemented heavy load testing, read the full report. NEED LUCOST PICTURE","title":"Accounting"},{"location":"accounting/#accounting","text":"","title":"Accounting"},{"location":"accounting/#authentication-and-authorization","text":"We have chosen JWT (JSON Web Token) as our authentication mechanism due to its strong security features and efficient performance. For implementation, we use the Simple JWT package, which provides a convenient and customizable solution for managing tokens. Roles: Superuser: Has full access to the admin panel and all information across the platform. Company: Designed for company customers to manage job postings and handle applications. User: Intended for job seekers who wish to create profiles, browse, and apply for jobs.","title":"Authentication and Authorization"},{"location":"accounting/#flow-for-job-seekers","text":"User Authentication: To sign up or log in to our application, users can interact with the /account/user/login endpoint. This endpoint accepts the user's email, which should be included in the body of the request. Handling New Users: If the email provided is new (i.e., not yet registered), a new user object is created in the database with that email. Once the account is successfully created, a JWT (JSON Web Token) is generated and sent to the provided email for authentication purposes. Profile Creation: Our Django application has a signal that automatically creates a user profile whenever a new account is registered. This eliminates the need to query the user table for details, as the profile data will be managed in a separate table.","title":"flow for job seekers:"},{"location":"accounting/#flow-for-company-customer","text":"Account Creation: Company customers must contact our support team to have an account created. The support team will ensure that the account is set up with the necessary profile details. There is no public endpoint available for company customers to create accounts themselves. Login Process: Once the account is created by support, company customers can log in using their company email through the standard login process.","title":"flow for company customer:"},{"location":"accounting/#model","text":"NEED FURTHER RESEARCH","title":"model"},{"location":"accounting/#schema","text":"Full Schema","title":"schema"},{"location":"accounting/#testing","text":"","title":"Testing"},{"location":"accounting/#integration-test","text":"This app has been thoroughly tested to ensure full functionality and reliability","title":"integration test"},{"location":"accounting/#load-test","text":"The most critical endpoint in this section is user sign-up, due to its role in writing data to the database. We focused extensively on this endpoint by simulating the creation of 2 million users with randomly generated emails using Locust. Statistics indicate that under heavy load, the endpoint performs with a 99th percentile latency of 100 ms and an average latency of 70 ms, which meets our performance expectations. For more details on how we implemented heavy load testing, read the full report. NEED LUCOST PICTURE","title":"load test"},{"location":"analytics/","text":"Details to be Added Shortly","title":"analytics"},{"location":"analytics/#details-to-be-added-shortly","text":"","title":"Details to be Added Shortly"},{"location":"cash/","text":"Details to be Added Shortly","title":"Cash strategies"},{"location":"cash/#details-to-be-added-shortly","text":"","title":"Details to be Added Shortly"},{"location":"celery/","text":"Details to be Added Shortly","title":"Background processing"},{"location":"celery/#details-to-be-added-shortly","text":"","title":"Details to be Added Shortly"},{"location":"high-pressure/","text":"Details to be Added Shortly","title":"High Pressure"},{"location":"high-pressure/#details-to-be-added-shortly","text":"","title":"Details to be Added Shortly"},{"location":"job/","text":"Details to be Added Shortly flow of jobs The core concepts of this project are outlined in the app. Our primary goal is to help companies find the best candidates, while enabling job seekers to land their dream jobs. To begin, companies should start by posting their job openings. In this project, our goal is to closely simulate the operations of a real startup by working with real-world data. To achieve this, we sourced a dataset from Kaggle containing approximately 1.6 million rows of CSV data . After performing some initial data cleaning, we proceeded to make 50 requests per second , saving the data into our database. This process was facilitated using the Locust tool for load testing. More details can be found here After enabling companies to save job listings, the most critical endpoint for job seekers became the one that lists all available jobs. Due to the high volume of job listings, querying the job table and displaying all jobs at once was impractical. Our initial solution was to implement pagination , which allowed the endpoint to function properly but resulted in unsatisfactory response times. Upon further investigation, we identified an N+1 query problem in this endpoint. After a quick fix, the endpoint became more stable, but our goal was to achieve response times under 100ms due to the importance of this feature. The final step was implementing caching , which we achieved using Redis. With caching in place, the endpoint is now both fast and reliable. more information on caching The remaining endpoint was relatively straightforward to handle. The final requirement was ensuring that job seekers could apply for jobs, and companies could view applications and update their status accordingly. models Our job application system consists of three core models. JobCategory A simple model was implemented for saving multiple job categories. This model is crucial, even in the early stages of the project, as it ensures that companies categorize their saved jobs from the start, preventing data inconsistencies in the job table later on. Job This is the primary model used for saving job listings. Companies are required to provide all critical information necessary to post their job openings. JobApply This model is used to save job applications from job seekers. Notably, job seekers can currently apply for a job only once and are unable to modify their application details afterward. schema Full Schema","title":"Job"},{"location":"job/#details-to-be-added-shortly","text":"","title":"Details to be Added Shortly"},{"location":"job/#flow-of-jobs","text":"The core concepts of this project are outlined in the app. Our primary goal is to help companies find the best candidates, while enabling job seekers to land their dream jobs. To begin, companies should start by posting their job openings. In this project, our goal is to closely simulate the operations of a real startup by working with real-world data. To achieve this, we sourced a dataset from Kaggle containing approximately 1.6 million rows of CSV data . After performing some initial data cleaning, we proceeded to make 50 requests per second , saving the data into our database. This process was facilitated using the Locust tool for load testing. More details can be found here After enabling companies to save job listings, the most critical endpoint for job seekers became the one that lists all available jobs. Due to the high volume of job listings, querying the job table and displaying all jobs at once was impractical. Our initial solution was to implement pagination , which allowed the endpoint to function properly but resulted in unsatisfactory response times. Upon further investigation, we identified an N+1 query problem in this endpoint. After a quick fix, the endpoint became more stable, but our goal was to achieve response times under 100ms due to the importance of this feature. The final step was implementing caching , which we achieved using Redis. With caching in place, the endpoint is now both fast and reliable. more information on caching The remaining endpoint was relatively straightforward to handle. The final requirement was ensuring that job seekers could apply for jobs, and companies could view applications and update their status accordingly.","title":"flow of jobs"},{"location":"job/#models","text":"Our job application system consists of three core models.","title":"models"},{"location":"job/#jobcategory","text":"A simple model was implemented for saving multiple job categories. This model is crucial, even in the early stages of the project, as it ensures that companies categorize their saved jobs from the start, preventing data inconsistencies in the job table later on.","title":"JobCategory"},{"location":"job/#job","text":"This is the primary model used for saving job listings. Companies are required to provide all critical information necessary to post their job openings.","title":"Job"},{"location":"job/#jobapply","text":"This model is used to save job applications from job seekers. Notably, job seekers can currently apply for a job only once and are unable to modify their application details afterward.","title":"JobApply"},{"location":"job/#schema","text":"Full Schema","title":"schema"},{"location":"models/","text":"Database schema","title":"Database schema"},{"location":"models/#database-schema","text":"","title":"Database schema"}]}